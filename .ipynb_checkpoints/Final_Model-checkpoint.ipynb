{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce621b4b-27c7-483f-aa67-105ee9f5b1f6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6c6d84-c0d0-49a1-a477-25c049bb1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c845d-b431-442e-8dc9-59a532c5d989",
   "metadata": {},
   "source": [
    "### Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f7d976-1932-4bd5-bf58-470f1a2e50ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Logistic Regression Classifier:\n",
      "F1 Score: 0.936586453281677\n",
      "Recall: 0.9369158878504673\n",
      "Precision: 0.9362984203652466\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Data\n",
    "existing_df_3 = pd.read_csv(\"Datasets/Existing_Companies.csv\", encoding='unicode_escape')\n",
    "existing_unicorn_data = existing_df_3[['Country', 'Industry']]\n",
    "\n",
    "# Encoding Country\n",
    "enc_country = OneHotEncoder()\n",
    "country_encoded = enc_country.fit_transform(existing_unicorn_data[['Country']]).toarray()\n",
    "country_encoded_df = pd.DataFrame(country_encoded, columns=enc_country.get_feature_names_out(['Country']))\n",
    "\n",
    "# Encoding Industry\n",
    "enc_industry = OneHotEncoder()\n",
    "industry_encoded = enc_industry.fit_transform(existing_unicorn_data[['Industry']]).toarray()\n",
    "industry_encoded_df = pd.DataFrame(industry_encoded, columns=enc_industry.get_feature_names_out(['Industry']))\n",
    "\n",
    "# Combine encoded country and industry into one dataset\n",
    "existing_unicorn_data = pd.concat([country_encoded_df, industry_encoded_df], axis=1)\n",
    "\n",
    "# Analyze the distribution of industries and countries\n",
    "industry_distribution = existing_unicorn_data.filter(like='Industry_').sum().to_dict()\n",
    "country_distribution = existing_unicorn_data.filter(like='Country_').sum().to_dict()\n",
    "\n",
    "# Define industry_country_counts\n",
    "industry_country_counts = {}\n",
    "for industry in industry_distribution:\n",
    "    industry_country_counts[industry] = {}\n",
    "    for country in country_distribution:\n",
    "        industry_country_counts[industry][country] = existing_unicorn_data[(existing_unicorn_data[industry] == 1) & (existing_unicorn_data[country] == 1)].shape[0]\n",
    "\n",
    "# Define a function to assign likelihood labels dynamically based on distribution\n",
    "def assign_likelihood_dynamic(row, industry_country_counts):\n",
    "    likelihood = 0  # Default: low chance\n",
    "\n",
    "    # Check each combination of industry and country\n",
    "    for industry, country_count_dict in industry_country_counts.items():\n",
    "        if row[industry] == 1:\n",
    "            for country, count in country_count_dict.items():\n",
    "                if row[country] == 1:\n",
    "                    if count > 35:  # Example threshold for high chance\n",
    "                        likelihood = 2  # High chance\n",
    "                    elif count > 10:  # Example threshold for medium chance\n",
    "                        likelihood = 1  # Medium chance\n",
    "                    return likelihood  # If combination found, return likelihood\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "# Apply the function to assign likelihood labels\n",
    "existing_unicorn_data['Likelihood'] = existing_unicorn_data.apply(assign_likelihood_dynamic, axis=1, industry_country_counts=industry_country_counts)\n",
    "\n",
    "# Train the Models\n",
    "X = existing_unicorn_data.drop('Likelihood', axis=1)\n",
    "y = existing_unicorn_data['Likelihood']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "clf_lr = LogisticRegression(random_state=42)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the Logistic Regression classifier\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "\n",
    "# Calculate Metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "f1 = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "precision = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "# Print Metrics\n",
    "print(\"Metrics for Logistic Regression Classifier:\")\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d544ce9-cc3c-42ff-b700-aff070c72d71",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb8a2e8-5013-457c-a4fe-a8e50c672a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Support Vector Machines (SVM) classifier:\n",
      "F1 Score: 0.9489401991326125\n",
      "Recall: 0.9485981308411215\n",
      "Precision: 0.9550031417682909\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Data\n",
    "existing_df_3 = pd.read_csv(\"Datasets/Existing_Companies.csv\", encoding='unicode_escape')\n",
    "existing_unicorn_data = existing_df_3[['Country', 'Industry']]\n",
    "\n",
    "# Encoding Country\n",
    "enc_country = OneHotEncoder()\n",
    "country_encoded = enc_country.fit_transform(existing_unicorn_data[['Country']]).toarray()\n",
    "country_encoded_df = pd.DataFrame(country_encoded, columns=enc_country.get_feature_names_out(['Country']))\n",
    "\n",
    "# Encoding Industry\n",
    "enc_industry = OneHotEncoder()\n",
    "industry_encoded = enc_industry.fit_transform(existing_unicorn_data[['Industry']]).toarray()\n",
    "industry_encoded_df = pd.DataFrame(industry_encoded, columns=enc_industry.get_feature_names_out(['Industry']))\n",
    "\n",
    "# Combine encoded country and industry into one dataset\n",
    "existing_unicorn_data = pd.concat([country_encoded_df, industry_encoded_df], axis=1)\n",
    "\n",
    "# Analyze the distribution of industries and countries\n",
    "industry_distribution = existing_unicorn_data.filter(like='Industry_').sum().to_dict()\n",
    "country_distribution = existing_unicorn_data.filter(like='Country_').sum().to_dict()\n",
    "\n",
    "# Define industry_country_counts\n",
    "industry_country_counts = {}\n",
    "for industry in industry_distribution:\n",
    "    industry_country_counts[industry] = {}\n",
    "    for country in country_distribution:\n",
    "        industry_country_counts[industry][country] = existing_unicorn_data[(existing_unicorn_data[industry] == 1) & (existing_unicorn_data[country] == 1)].shape[0]\n",
    "\n",
    "# Define a function to assign likelihood labels dynamically based on distribution\n",
    "def assign_likelihood_dynamic(row, industry_country_counts):\n",
    "    likelihood = 0  # Default: low chance\n",
    "\n",
    "    # Check each combination of industry and country\n",
    "    for industry, country_count_dict in industry_country_counts.items():\n",
    "        if row[industry] == 1:\n",
    "            for country, count in country_count_dict.items():\n",
    "                if row[country] == 1:\n",
    "                    if count > 35:  # Example threshold for high chance\n",
    "                        likelihood = 2  # High chance\n",
    "                    elif count > 10:  # Example threshold for medium chance\n",
    "                        likelihood = 1  # Medium chance\n",
    "                    return likelihood  # If combination found, return likelihood\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "# Apply the function to assign likelihood labels\n",
    "existing_unicorn_data['Likelihood'] = existing_unicorn_data.apply(assign_likelihood_dynamic, axis=1, industry_country_counts=industry_country_counts)\n",
    "\n",
    "# Train the Models\n",
    "X = existing_unicorn_data.drop('Likelihood', axis=1)\n",
    "y = existing_unicorn_data['Likelihood']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Support Vector Machines (SVM) classifier\n",
    "clf_svm = SVC(kernel='linear', random_state=42)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the Support Vector Machines (SVM) classifier\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "# Calculate Metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "f1 = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "precision = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "# Print Metrics\n",
    "print(\"Metrics for Support Vector Machines (SVM) classifier:\")\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191eb17-10db-47ab-a204-d42819960b5d",
   "metadata": {},
   "source": [
    "### Cross Validation (n_splits) = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3950fe34-9703-406b-84b6-7f045634f8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Logistict Regression: 0.9287889447236182\n",
      "Cross-Validation Accuracy SVM: 0.9979949748743719\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Data\n",
    "existing_df_3 = pd.read_csv(\"Datasets/Existing_Companies.csv\", encoding='unicode_escape')\n",
    "existing_unicorn_data = existing_df_3[['Country', 'Industry']]\n",
    "\n",
    "# Encoding Country\n",
    "enc_country = OneHotEncoder()\n",
    "country_encoded = enc_country.fit_transform(existing_unicorn_data[['Country']]).toarray()\n",
    "country_encoded_df = pd.DataFrame(country_encoded, columns=enc_country.get_feature_names_out(['Country']))\n",
    "\n",
    "# Encoding Industry\n",
    "enc_industry = OneHotEncoder()\n",
    "industry_encoded = enc_industry.fit_transform(existing_unicorn_data[['Industry']]).toarray()\n",
    "industry_encoded_df = pd.DataFrame(industry_encoded, columns=enc_industry.get_feature_names_out(['Industry']))\n",
    "\n",
    "# Combine encoded country and industry into one dataset\n",
    "existing_unicorn_data = pd.concat([country_encoded_df, industry_encoded_df], axis=1)\n",
    "\n",
    "# Analyze the distribution of industries and countries\n",
    "industry_distribution = existing_unicorn_data.filter(like='Industry_').sum().to_dict()\n",
    "country_distribution = existing_unicorn_data.filter(like='Country_').sum().to_dict()\n",
    "\n",
    "# Define industry_country_counts\n",
    "industry_country_counts = {}\n",
    "for industry in industry_distribution:\n",
    "    industry_country_counts[industry] = {}\n",
    "    for country in country_distribution:\n",
    "        industry_country_counts[industry][country] = existing_unicorn_data[(existing_unicorn_data[industry] == 1) & (existing_unicorn_data[country] == 1)].shape[0]\n",
    "\n",
    "# Define a function to assign likelihood labels dynamically based on distribution\n",
    "def assign_likelihood_dynamic(row, industry_country_counts):\n",
    "    likelihood = 0  # Default: low chance\n",
    "\n",
    "    # Check each combination of industry and country\n",
    "    for industry, country_count_dict in industry_country_counts.items():\n",
    "        if row[industry] == 1:\n",
    "            for country, count in country_count_dict.items():\n",
    "                if row[country] == 1:\n",
    "                    if count > 35:  # Example threshold for high chance\n",
    "                        likelihood = 2  # High chance\n",
    "                    elif count > 10:  # Example threshold for medium chance\n",
    "                        likelihood = 1  # Medium chance\n",
    "                    return likelihood  # If combination found, return likelihood\n",
    "\n",
    "    return likelihood\n",
    "\n",
    "# Apply the function to assign likelihood labels\n",
    "existing_unicorn_data['Likelihood'] = existing_unicorn_data.apply(assign_likelihood_dynamic, axis=1, industry_country_counts=industry_country_counts)\n",
    "\n",
    "# Train the Models\n",
    "X = existing_unicorn_data.drop('Likelihood', axis=1)\n",
    "y = existing_unicorn_data['Likelihood']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Define the cross-validation method\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and evaluate the model\n",
    "cv_scores_lr = cross_val_score(clf_lr, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "cv_scores_svm = cross_val_score(clf_svm, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "print(\"Cross-Validation Accuracy Logistict Regression:\", cv_scores_lr.mean())\n",
    "print(\"Cross-Validation Accuracy SVM:\", cv_scores_svm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6074c4-9334-499b-b416-577935d7f747",
   "metadata": {},
   "source": [
    "### Cross Validation (n_splits) = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40d4bee-c61b-4994-b379-de756110a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Logistict Regression: 0.9288080808080809\n",
      "Cross-Validation Accuracy SVM: 0.998\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to assign likelihood labels\n",
    "existing_unicorn_data['Likelihood'] = existing_unicorn_data.apply(assign_likelihood_dynamic, axis=1, industry_country_counts=industry_country_counts)\n",
    "\n",
    "# Train the Models\n",
    "X = existing_unicorn_data.drop('Likelihood', axis=1)\n",
    "y = existing_unicorn_data['Likelihood']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Define the cross-validation method\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and evaluate the model\n",
    "cv_scores_lr = cross_val_score(clf_lr, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "cv_scores_svm = cross_val_score(clf_svm, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "print(\"Cross-Validation Accuracy Logistict Regression:\", cv_scores_lr.mean())\n",
    "print(\"Cross-Validation Accuracy SVM:\", cv_scores_svm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0982d-58e5-40d3-9b9a-e14d39335bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
